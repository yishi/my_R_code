
####################################################################################
###  spell checker for English Text
###  more details please refer below link
### http://www.sumsar.net/blog/2014/12/peter-norvigs-spell-checker-in-two-lines-of-r/
#####################################################################################

# Read in big.txt, a 6.5 mb collection of different English texts.
# you could get this file from http://www.norvig.com/big.txt
raw_text <- paste(readLines("big.txt"), collapse = " ")

# Make the text lowercase and split it up creating a huge vector of word tokens.
split_text <- strsplit(tolower(raw_text), "[^a-z]+")
# Count the number of different type of words.
word_count <- table(split_text)
# Sort the words and create an ordered vector with the most common type of words first.
sorted_words <- names(sort(word_count, decreasing = TRUE))

correct <- function(word) {
  
  # Calculate the edit distance between the word and all other words in sorted_words.
  edit_dist <- adist(word, sorted_words)
  # Calculate the minimum edit distance to find a word that exists in big.txt 
  # with a limit of two edits.
  min_edit_dist <- min(edit_dist, 2)
  # Generate a vector with all words with this minimum edit distance.
  # Since sorted_words is ordered from most common to least common, the resulting
  # vector will have the most common / probable match first.
  proposals_by_prob <- c(sorted_words[ edit_dist <= min_edit_dist])
  # In case proposals_by_prob would be empty we append the word to be corrected...
  proposals_by_prob <- c(proposals_by_prob, word)
  # ... and return the first / most probable word in the vector.
  proposals_by_prob[1]
}

correct('speling')
# [1] "spelling"


######################################################################
### spell checker for chinese text
######################################################################

########################################
###  corpus source 1: news on the line 
# you could get this file from paste some news on the internet together
raw_text <- paste(readLines("yourfile.txt"), collapse = " ")

# segment sentence
# set stopwords is empty
source('f_segment_ch.R')
# f_segment_ch.R
# library(jiebaR)
# f_segment_ch <- function(text, type = "mix", 
#                          user_dict_path = "D:/application/R/library/jiebaRD/dict/user.dict.e.utf8",
#                          stop_word_path = STOPPATH) {
#   
#   # segment sentence
#   cutter <- worker(type = type, byline = TRUE, 
#                    user = user_dict_path, 
#                    stop_word = stop_word_path)
#   segment(text, cutter)
#   
# }


text_seg <- f_segment_ch(text = raw_text, type = "mp",
                         stop_word_path = "D:/application/R/library/jiebaRD/dict/stop_words_empty.utf8")

# delete english and numbers and space
text_seg2 <- gsub("[a-z0-9[:space:]]", '', text_seg[[1]])
text_seg3 <- text_seg2[text_seg2 != '']

word_count <- table(text_seg3)
sorted_words <- names(sort(word_count, decreasing = TRUE))
# save sorted_words as txt, and read it directly in the future

########################################
###  corpus source 2: dictionary
dict <- readLines("D:/application/R/library/jiebaRD/dict/user.dict.e.utf8", 
                  encoding = "UTF-8")

########################################
### combine two source corpus
tot <- c(sorted_words, dict)

correct <- function(word, corpus = tot) {

  # Calculate the edit distance between the word and all other words in corpus
  edit_dist <- adist(word, corpus)
  # Calculate the minimum edit distance to find a word that exists in corpus
  # with a limit of two edits.
  min_edit_dist <- min(edit_dist, 2)
  # Generate a vector with all words with this minimum edit distance.
  proposals_by_prob <- c(corpus[ edit_dist <= min_edit_dist])
  # In case proposals_by_prob would be empty we append the word to be corrected...
  proposals_by_prob <- c(proposals_by_prob, word)
  # return the first three word in the vector.
  if (length(proposals_by_prob) < 3) {
    proposals_by_prob
  } else {
    proposals_by_prob[1:3]
  }
  
}


correct('电里')
# "电力" "电网" "电厂"
